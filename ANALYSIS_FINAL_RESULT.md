# 📊 최종 전략(0.8765) 결과 분석 및 향후 로드맵

## 1️⃣ 결과 해석: 왜 0.8886(Best)보다 떨어졌는가?

| 모델 | MAP | MRR | 구성 |
|------|-----|-----|------|
| **submission_33** | **0.8886** | **0.89xx** | SBERT + Hard Voting + **단일 쿼리** |
| **submission_final** | 0.8765 | 0.8803 | SBERT + Hard Voting + **Multi-Query** |

### 📉 원인: Multi-Query의 역효과 (Noise)
- **의도**: 쿼리를 3개로 늘려 재현율(Recall)을 높이려 했습니다.
- **실제**: 우리 시스템(BM25+SBERT)에서는 추가된 쿼리들이 **관련 없는 문서(Noise)**를 후보군에 섞어버렸습니다.
- **결과**: Reranker가 정답을 찾기 더 어려워져 정밀도(Precision)가 하락했습니다.
- **교훈**: 현재 모델 조합(SBERT)에서는 **"잘 다듬어진 단일 쿼리(HyDE)"**가 최적입니다.

---

## 2️⃣ 동료(0.9174)와의 진짜 차이점은?

우리가 Multi-Query를 따라 했음에도 점수가 떨어진 이유는 **"기초 체력(임베딩 모델)"** 차이 때문입니다.

| 항목 | 우리 시스템 | 동료 시스템 (0.9174) |
|------|------------|---------------------|
| **임베딩** | SBERT (768 dim) | **E5-large (1024 dim)** |
| **특징** | 한국어 특화지만 구형 모델 | **다국어 최신 SOTA 모델** |
| **Multi-Query** | Noise가 됨 | **강력한 임베딩이 Noise를 걸러냄** |

> **결론**: SBERT로는 한계(0.8886)에 도달했습니다. 0.90 이상으로 가려면 **E5 임베딩 도입**이 필수입니다.

---

## 3️⃣ 점수 상승을 위한 필승 전략 (Roadmap)

### 🚀 Step 1: E5 임베딩 구축 (지금 즉시)
- 동료가 사용한 `intfloat/multilingual-e5-large` 모델로 문서를 임베딩합니다.
- FAISS 인덱스를 구축하여 고속 검색 환경을 만듭니다.

### 🚀 Step 2: 검색 파이프라인 교체
- 기존: `SBERT + Gemini + BM25`
- 변경: `E5 + Gemini + BM25` (SBERT를 E5로 대체)
- 기대 효과: 임베딩 성능 향상으로 **MAP 0.90+** 진입

### 🚀 Step 3: 가중치 재조정
- E5는 성능이 좋으므로, 동료처럼 **Dense 가중치를 높이는 전략**이 비로소 유효해집니다.
- 이때 Multi-Query를 다시 도입하면 시너지가 날 것입니다.

---

## ⚡️ Action Plan

1.  **E5 인덱싱 스크립트 실행** (약 5~10분 소요 예상)
2.  인덱싱 완료 후, 검색 파이프라인에 E5 적용
3.  새로운 하이브리드 검색으로 제출 파일 생성

**지금 바로 E5 인덱싱을 시작합니다.**
