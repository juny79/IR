import json
from models.llm_client import llm_client
from retrieval.hybrid_search import run_hybrid_search
from retrieval.es_connector import es

# ğŸ¯ íŒŒë¼ë¯¸í„°: Hard Voting ê°€ì¤‘ì¹˜ (í™˜ê²½ì— ë”°ë¼ ë³€ê²½)
VOTING_WEIGHTS = [7, 4, 2]  # í…ŒìŠ¤íŠ¸: [7, 4, 2] (ê¸°ë³¸: [5, 3, 1], íŠœë‹: [6, 3, 1])

def answer_question_optimized(messages):
    res = {"standalone_query": "", "topk": [], "answer": ""}
    analysis = llm_client.analyze_query(messages)
    
    if analysis.tool_calls:
        query = json.loads(analysis.tool_calls[0].function.arguments)['standalone_query']
        res["standalone_query"] = query
        
        # â­ Phase 2: HyDEë¥¼ ì „ì²´ì— ì ìš© (ì¼ê´€ëœ íŒŒì´í”„ë¼ì¸)
        hypothetical_answer = llm_client.generate_hypothetical_answer(query)
        
        # HyDE í™•ì¥ ì¿¼ë¦¬ ìƒì„±
        if hypothetical_answer:
            hyde_query = f"{query}\n{hypothetical_answer}"
        else:
            hyde_query = query
        
        # Hybrid Search with Reranker ì‹¤í–‰ (HyDE ì „ì²´ ì ìš©)
        # - Sparse: HyDE í™•ì¥ ì¿¼ë¦¬ ì‚¬ìš©
        # - Dense: HyDE í™•ì¥ ì¿¼ë¦¬ ì‚¬ìš© (ì¼ê´€ì„±)
        # - Reranker: ì›ë³¸ ì¿¼ë¦¬ ì‚¬ìš© (ì •í™•í•œ relevance íŒë‹¨) â­
        # - Hard Voting: ìµœì í™”ëœ ê°€ì¤‘ì¹˜ ì‚¬ìš©
        final_ranked_results = run_hybrid_search(
            original_query=query,
            sparse_query=hyde_query,
            reranker_query=query,  # ì›ë³¸ ì¿¼ë¦¬ë¡œ ë³µêµ¬
            voting_weights=VOTING_WEIGHTS  # íŒŒë¼ë¯¸í„° íŠœë‹ìš© â­
        )
        
        # final_ranked_resultsëŠ” ì´ì œ docid ë¦¬ìŠ¤íŠ¸ í˜•íƒœ
        res["topk"] = final_ranked_results[:5]  # ìƒìœ„ 5ê°œ
        
        # ì»¨í…ìŠ¤íŠ¸ ìƒì„±: Top-3 ë¬¸ì„œ ë‚´ìš© ì‚¬ìš©
        context_docs = []
        for docid in final_ranked_results[:3]:
            # ESì—ì„œ docid í•„ë“œë¡œ ê²€ìƒ‰í•˜ì—¬ ì‹¤ì œ content ê°€ì ¸ì˜¤ê¸°
            search_result = es.search(
                index="test",
                query={"term": {"docid": docid}},
                size=1
            )
            if search_result['hits']['hits']:
                context_docs.append(search_result['hits']['hits'][0]['_source']['content'])
        
        context = " ".join(context_docs)
        res["answer"] = llm_client.generate_answer(messages, context)
    else:
        res["answer"] = analysis.content # ì¼ìƒ ëŒ€í™” ì‘ë‹µ
    
    return res