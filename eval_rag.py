import json
import os
from models.solar_client import solar_client
from retrieval.hybrid_search import run_hybrid_search
from retrieval.es_connector import es

# ğŸ¯ Phase 4D: ê³ ì„±ëŠ¥ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (ê²Œì´íŒ… ì—†ìŒ)
# MAP 0.8424 ë‹¬ì„± ì„¤ì •
# - Solar Pro 2 HyDE (300ì)
# - Hard Voting [5,4,2]
# - SBERT + Gemini embedding
# - ê²Œì´íŒ… ì •ì±… ì œê±° â†’ ëª¨ë“  ì§ˆë¬¸ ê²€ìƒ‰ ìˆ˜í–‰
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
def _env_bool(name: str, default: bool) -> bool:
    v = os.getenv(name)
    if v is None:
        return default
    v = v.strip().lower()
    return v in ("1", "true", "t", "yes", "y", "on")


def _env_int(name: str, default: int) -> int:
    v = os.getenv(name)
    if v is None:
        return default


    def _env_float(name: str, default: float) -> float:
        v = os.getenv(name)
        if v is None:
            return default
        try:
            return float(v)
        except Exception:
            return default
    try:
        return int(v)
    except Exception:
        return default


def _env_json_list(name: str, default_list):
    v = os.getenv(name)
    if not v:
        return default_list
    try:
        parsed = json.loads(v)
        if isinstance(parsed, list) and all(isinstance(x, int) for x in parsed):
            return parsed
    except Exception:
        pass
    return default_list


# ê¸°ë³¸ê°’(í˜„ì¬ ìµœê³ ì  ê·¼ì²˜ ì„¤ì •). ì‹¤í—˜ ëŸ¬ë„ˆì—ì„œ í™˜ê²½ë³€ìˆ˜ë¡œ ì˜¤ë²„ë¼ì´ë“œ ê°€ëŠ¥.
VOTING_WEIGHTS = _env_json_list("VOTING_WEIGHTS_JSON", [5, 4, 2])
USE_MULTI_EMBEDDING = _env_bool("USE_MULTI_EMBEDDING", True)   # SBERT + Gemini
USE_GEMINI_ONLY = _env_bool("USE_GEMINI_ONLY", False)
TOP_K_RETRIEVE = _env_int("TOP_K_RETRIEVE", 80)
USE_RRF = _env_bool("USE_RRF", False)
RRF_K = _env_int("RRF_K", 60)
USE_GATING = _env_bool("USE_GATING", False)
HYDE_MAX_LENGTH = _env_int("HYDE_MAX_LENGTH", 200)
USE_SOLAR_ANALYZER = _env_bool("USE_SOLAR_ANALYZER", True)

# is_science=falseì¼ ë•Œ(topk=[] ì •ì±…) ì ìš©í•  ìµœì†Œ ì‹ ë¢°ë„. ë‚®ìœ¼ë©´ ê²€ìƒ‰ìœ¼ë¡œ ê°•ì œ(ì˜¤íŒ ë°©ì§€).
NO_SEARCH_CONFIDENCE_THRESHOLD = _env_float("NO_SEARCH_CONFIDENCE_THRESHOLD", 0.0)

# í›„ë³´êµ°(ë¦¬ë­ì»¤ ì…ë ¥) í¬ê¸°
CANDIDATE_POOL_SIZE = _env_int("CANDIDATE_POOL_SIZE", 80)

def answer_question_optimized(messages):
    res = {"standalone_query": "", "topk": [], "answer": ""}
    solar_analysis = None
    # ì›ë¬¸ ì‚¬ìš©ì ì§ˆë¬¸(ê²€ìƒ‰/ë¦¬ë­ì»¤ ì¿¼ë¦¬ë¡œ ì‚¬ìš©): LLM rewriteë¡œ ì¸í•œ ì„±ëŠ¥ ì €í•˜ ë°©ì§€
    original_user_query = ""
    try:
        if isinstance(messages, list) and messages:
            original_user_query = messages[-1].get('content', '')
        else:
            original_user_query = str(messages)
    except Exception:
        original_user_query = str(messages)
    if USE_SOLAR_ANALYZER:
        solar_analysis = solar_client.analyze_query_and_hyde(messages, hyde_max_chars=HYDE_MAX_LENGTH)
        is_science_question = bool(solar_analysis.get("is_science", False))
        solar_confidence = float(solar_analysis.get("confidence", 0.0) or 0.0)
        # ì œì¶œìš©(standalone_query)ì€ Solar ì •ê·œí™” ê²°ê³¼ ì‚¬ìš©
        query_text = solar_analysis.get("standalone_query", "") or original_user_query
    else:
        # (ë ˆê±°ì‹œ) ì•ˆì „ì¥ì¹˜: Solar analyzer ë¹„í™œì„±í™” ì‹œ ëª¨ë“  ì§ˆë¬¸ ê²€ìƒ‰
        is_science_question = True
        solar_confidence = 1.0
        query_text = original_user_query
    
    res["standalone_query"] = query_text
    
    # ë¹„ê³¼í•™(ê²€ìƒ‰ ë¶ˆí•„ìš”) ì§ˆë¬¸: topk=[]
    # ë‹¨, ì‹ ë¢°ë„ê°€ ë‚®ìœ¼ë©´ ì˜¤íŒ ë°©ì§€ë¥¼ ìœ„í•´ ê²€ìƒ‰ìœ¼ë¡œ ê°•ì œ
    if (not is_science_question) and (solar_confidence >= NO_SEARCH_CONFIDENCE_THRESHOLD):
        res["topk"] = []
        if solar_analysis and solar_analysis.get("direct_answer"):
            res["answer"] = solar_analysis.get("direct_answer")
        else:
            res["answer"] = solar_client.generate_answer(messages, "")
        return res
    
    # Solar analyzerê°€ HyDEë¥¼ í•¨ê»˜ ìƒì„±í–ˆë‹¤ë©´ ì¬ì‚¬ìš©(LLM í˜¸ì¶œ 1íšŒ ì ˆê°)
    hypothetical_answer = ""
    if solar_analysis and solar_analysis.get("hyde"):
        hypothetical_answer = solar_analysis.get("hyde")
    else:
        hypothetical_answer = solar_client.generate_hypothetical_answer(query_text)
    
    # HyDE í™•ì¥ ì¿¼ë¦¬ ìƒì„±
    if hypothetical_answer:
        # SparseëŠ” ì •ê·œí™” standalone_query + HyDEë¡œ ì¬í˜„ìœ¨ í™•ë³´
        hyde_query = f"{query_text}\n{hypothetical_answer}"
    else:
        hyde_query = query_text
    
    # Hybrid Search with Reranker ì‹¤í–‰ (Phase 4D: [5,4,2] + TopK=50)
    final_ranked_results = run_hybrid_search(
        # Dense/ë¦¬ë­ì»¤ëŠ” ì›ë¬¸ ì§ˆë¬¸ ìœ ì§€(LLM rewriteë¡œ ì˜ë¯¸ê°€ ë°”ë€ŒëŠ” ë¦¬ìŠ¤í¬ ê°ì†Œ)
        original_query=original_user_query,
        sparse_query=hyde_query,
        reranker_query=original_user_query,
        voting_weights=VOTING_WEIGHTS,  # [5, 4, 2]
        use_multi_embedding=USE_MULTI_EMBEDDING,  # SBERT + Gemini
        top_k_retrieve=TOP_K_RETRIEVE,  # 50ê°œ
        candidate_pool_size=CANDIDATE_POOL_SIZE,
        use_gemini_only=USE_GEMINI_ONLY,
        use_rrf=USE_RRF,  # False (Hard Voting)
        rrf_k=RRF_K,
        multi_queries=[]  # Phase 4D: ë©€í‹° ì¿¼ë¦¬ ì—†ìŒ
    )
    
    # ê²€ìƒ‰ ê²°ê³¼ ì„¤ì •: í•­ìƒ ë°˜í™˜ (ê²Œì´íŒ… ì—†ìŒ)
    res["topk"] = final_ranked_results[:5]  # ìƒìœ„ 5ê°œ
    
    # ì»¨í…ìŠ¤íŠ¸ ìƒì„±: Top-3 ë¬¸ì„œ ë‚´ìš© ì‚¬ìš©
    context_docs = []
    for docid in final_ranked_results[:3]:
        search_result = es.search(
            index="test",
            query={"term": {"docid": docid}},
            size=1
        )
        if search_result['hits']['hits']:
            context_docs.append(search_result['hits']['hits'][0]['_source']['content'])
    
    context = " ".join(context_docs)
    # Solar Pro 2ë¡œ ìµœì¢… ë‹µë³€ ìƒì„±
    res["answer"] = solar_client.generate_answer(messages, context)
    
    return res