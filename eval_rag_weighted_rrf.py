"""
ğŸ¯ ë™ë£Œ ì½”ë“œ(MAP 0.9174) í•µì‹¬ ì „ëµ ë°˜ì˜ ë²„ì „

í•µì‹¬ ë³€ê²½ì :
1. ê°€ì¤‘ì¹˜ RRF (Weighted RRF): Denseì— ë” ë†’ì€ ê°€ì¤‘ì¹˜
   - W3_WEIGHTS = [0.6, 0.3, 0.3, 1.6, 1.0, 1.0]
   - BM25: q1=0.6, q2=0.3, q3=0.3
   - Dense: q1=1.6, q2=1.0, q3=1.0
   
2. Multi-Query 3ê´€ì :
   - q1: êµ¬ì²´ì  ì„œìˆ í˜• (ê°€ì¥ ì¤‘ìš”)
   - q2: í•µì‹¬ í‚¤ì›Œë“œ ë‚˜ì—´
   - q3: ìœ ì‚¬ í‘œí˜„/ë‹¤ë¥¸ ê´€ì 

3. íŒŒë¼ë¯¸í„°:
   - RRF_K = 60
   - TOP_CANDIDATES = 100
   - FINAL_TOPK = 5
"""

import json
import os
from models.solar_client import solar_client
from retrieval.es_connector import es, sparse_retrieve, dense_retrieve
from retrieval.reranker import reranker
from collections import defaultdict

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# íŒŒë¼ë¯¸í„° ì„¤ì • (ë™ë£Œ ì½”ë“œ ê¸°ì¤€)
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
RRF_K = 60
BM25_TOPN = 50
DENSE_TOPN = 50
TOP_CANDIDATES = 100
FINAL_TOPK = 5
HYDE_MAX_LENGTH = 200

# ê°€ì¤‘ì¹˜ RRF: [BM25_q1, BM25_q2, BM25_q3, Dense_q1, Dense_q2, Dense_q3]
W3_WEIGHTS = [0.6, 0.3, 0.3, 1.6, 1.0, 1.0]


def _env_bool(name: str, default: bool) -> bool:
    v = os.getenv(name)
    if v is None:
        return default
    return v.strip().lower() in ("1", "true", "yes", "on")


USE_WEIGHTED_RRF = _env_bool("USE_WEIGHTED_RRF", True)
USE_MULTI_QUERY_3 = _env_bool("USE_MULTI_QUERY_3", True)


def reciprocal_rank_fusion_weighted(rank_lists, k=60, weights=None):
    """
    ê°€ì¤‘ì¹˜ RRF (ë™ë£Œ ì½”ë“œ ë°©ì‹)
    
    Args:
        rank_lists: List[List[docid]] - ê° ê²€ìƒ‰ ê²°ê³¼ì˜ docid ìˆœìœ„ ë¦¬ìŠ¤íŠ¸
        k: RRF íŒŒë¼ë¯¸í„°
        weights: ê° rank_listì— ëŒ€í•œ ê°€ì¤‘ì¹˜ (ê¸¸ì´ê°€ rank_listsì™€ ê°™ì•„ì•¼ í•¨)
    
    Returns:
        ì •ë ¬ëœ docid ë¦¬ìŠ¤íŠ¸
    """
    if weights is None:
        weights = [1.0] * len(rank_lists)
    
    # ê¸¸ì´ ë¶ˆì¼ì¹˜ ë°©ì–´
    if len(rank_lists) != len(weights):
        m = min(len(rank_lists), len(weights))
        rank_lists = rank_lists[:m]
        weights = weights[:m]
    
    scores = {}
    for w, rank_list in zip(weights, rank_lists):
        for rank, doc_id in enumerate(rank_list):
            scores[doc_id] = scores.get(doc_id, 0.0) + w * (1.0 / (k + rank + 1))
    
    return sorted(scores.keys(), key=lambda x: scores[x], reverse=True)


def generate_multi_query_3(query_text, messages=None):
    """
    3ê´€ì  Multi-Query ìƒì„± (ë™ë£Œ ì½”ë“œ ë°©ì‹)
    
    Returns:
        queries: [êµ¬ì²´ì  ì„œìˆ í˜•, í•µì‹¬ í‚¤ì›Œë“œ, ìœ ì‚¬ í‘œí˜„]
    """
    system_prompt = """ë‹¹ì‹ ì€ ê³¼í•™ ê²€ìƒ‰ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ í•´ê²°í•˜ê¸° ìœ„í•´ ê²€ìƒ‰ì—”ì§„ì— ì…ë ¥í•  '3ê°€ì§€ ë²„ì „ì˜ ê²€ìƒ‰ì–´'ë¥¼ JSONìœ¼ë¡œ ìƒì„±í•˜ì„¸ìš”.

[ì¶œë ¥ JSON í˜•ì‹]
{
    "is_science": true/false,
    "queries": [
        "êµ¬ì²´ì ì´ê³  ì™„ê²°ëœ ì„œìˆ í˜• ì§ˆë¬¸ (ê°€ì¥ ì¤‘ìš”)",
        "í•µì‹¬ í‚¤ì›Œë“œ ë‚˜ì—´ (ëª…ì‚¬ ì¤‘ì‹¬)",
        "ìœ ì‚¬í•œ ì˜ë¯¸ì˜ ë‹¤ë¥¸ í‘œí˜„ ì§ˆë¬¸"
    ],
    "hyde": "ê°€ì„¤ì  ë‹µë³€ (200ì ì´ë‚´, ë¬¸ì„œì— ìˆì„ ë²•í•œ ë‚´ìš©)"
}

[íŒë‹¨ ê¸°ì¤€]
- is_science=true: ì§€ì‹/ê³¼í•™/ê¸°ìˆ /ì—­ì‚¬/ì‚¬íšŒ/ë¬¸í™” ë“± ì½”í¼ìŠ¤ì—ì„œ ê·¼ê±°ë¥¼ ì°¾ì•„ì•¼ í•˜ëŠ” ì§ˆë¬¸
- is_science=false: ì¸ì‚¬/ì¡ë‹´/ê°ì •í‘œí˜„/ë©”íƒ€ëŒ€í™” (ì•ˆë…•, ê³ ë§ˆì›Œ, ë„ˆ ëˆ„êµ¬ì•¼)"""

    try:
        if messages and isinstance(messages, list):
            call_messages = [{"role": "system", "content": system_prompt}] + messages
        else:
            call_messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": query_text}
            ]
        
        response = solar_client.client.chat.completions.create(
            model=solar_client.model,
            messages=call_messages,
            temperature=0,
            response_format={"type": "json_object"}
        )
        
        raw = response.choices[0].message.content
        result = json.loads(raw)
        
        is_science = bool(result.get("is_science", True))
        queries = result.get("queries", [])
        hyde = result.get("hyde", "")
        
        if not isinstance(queries, list):
            queries = []
        queries = [str(q).strip() for q in queries if str(q).strip()]
        
        # queries ë¹„ì—ˆìœ¼ë©´ ì›ë³¸ ì¿¼ë¦¬ë¡œ fallback
        if not queries:
            queries = [query_text]
        
        # 3ê°œê¹Œì§€ë§Œ
        queries = queries[:3]
        
        return {
            "is_science": is_science,
            "queries": queries,
            "hyde": hyde
        }
        
    except Exception as e:
        # fallback
        return {
            "is_science": True,
            "queries": [query_text],
            "hyde": ""
        }


def get_documents_batch(docids):
    """ì—¬ëŸ¬ ë¬¸ì„œë¥¼ í•œë²ˆì— ê°€ì ¸ì˜¤ê¸°"""
    try:
        result = es.search(
            index="test",
            query={"terms": {"docid": docids}},
            size=len(docids),
            _source=["docid", "content"]
        )
        
        docs_dict = {}
        for hit in result['hits']['hits']:
            doc_id = hit['_source']['docid']
            content = hit['_source'].get('content', '')[:1000]
            docs_dict[doc_id] = content
        
        return docs_dict
    except:
        return {}


def answer_question_weighted_rrf(messages):
    """
    ë™ë£Œ ì½”ë“œ(0.9174) í•µì‹¬ ì „ëµ ë°˜ì˜ ë²„ì „
    - 3ê´€ì  Multi-Query
    - ê°€ì¤‘ì¹˜ RRF (Dense > BM25)
    - TOP_CANDIDATES=100
    """
    res = {"standalone_query": "", "topk": [], "answer": ""}
    
    # ì›ë³¸ ì‚¬ìš©ì ì§ˆë¬¸
    original_user_query = ""
    try:
        if isinstance(messages, list) and messages:
            original_user_query = messages[-1].get('content', '')
        else:
            original_user_query = str(messages)
    except:
        original_user_query = str(messages)
    
    # Step 1: 3ê´€ì  Multi-Query + ê²Œì´íŒ… + HyDE ìƒì„±
    mq_result = generate_multi_query_3(original_user_query, messages)
    
    is_science = mq_result.get("is_science", True)
    queries = mq_result.get("queries", [original_user_query])
    hyde = mq_result.get("hyde", "")
    
    # ê°€ì¥ êµ¬ì²´ì ì¸ ì²« ë²ˆì§¸ ì¿¼ë¦¬ë¥¼ standalone_queryë¡œ
    main_query = queries[0] if queries else original_user_query
    res["standalone_query"] = main_query
    
    # ê²Œì´íŒ…: ë¹„ê³¼í•™ ì§ˆë¬¸ì€ topk=[]
    if not is_science:
        res["topk"] = []
        res["answer"] = solar_client.generate_answer(messages, "")
        return res
    
    # Step 2: ê° ì¿¼ë¦¬ë§ˆë‹¤ BM25 + Dense ê²€ìƒ‰
    all_bm25_lists = []
    all_dense_lists = []
    
    for q in queries:
        # BM25 ê²€ìƒ‰ (HyDE í™•ì¥)
        hyde_q = f"{q}\n{hyde}" if hyde else q
        bm25_res = sparse_retrieve(hyde_q, BM25_TOPN)
        bm25_docids = [hit['_source']['docid'] for hit in bm25_res['hits']['hits']]
        all_bm25_lists.append(bm25_docids)
        
        # Dense ê²€ìƒ‰ (SBERT)
        dense_res = dense_retrieve(q, DENSE_TOPN, "embeddings_sbert")
        dense_docids = [hit['_source']['docid'] for hit in dense_res['hits']['hits']]
        all_dense_lists.append(dense_docids)
    
    # Step 3: ê°€ì¤‘ì¹˜ RRF ìœµí•©
    # rank_lists = [BM25_q1, BM25_q2, BM25_q3, Dense_q1, Dense_q2, Dense_q3]
    rank_lists = all_bm25_lists + all_dense_lists
    
    # 3ì¿¼ë¦¬ì¼ ë•Œë§Œ W3 ê°€ì¤‘ì¹˜ ì ìš© (ê¸¸ì´ 6)
    if USE_WEIGHTED_RRF and len(rank_lists) == 6:
        weights = W3_WEIGHTS
    else:
        weights = [1.0] * len(rank_lists)
    
    candidate_docids = reciprocal_rank_fusion_weighted(
        rank_lists,
        k=RRF_K,
        weights=weights
    )
    
    top_candidates = candidate_docids[:TOP_CANDIDATES]
    
    if not top_candidates:
        res["topk"] = []
        res["answer"] = "ë¬¸ì„œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
        return res
    
    # Step 4: ë¬¸ì„œ ë‚´ìš© ê°€ì ¸ì˜¤ê¸° + Reranker
    docs_dict = get_documents_batch(top_candidates)
    docs_with_content = [(doc_id, docs_dict.get(doc_id, ''))
                         for doc_id in top_candidates if docs_dict.get(doc_id)]
    
    if docs_with_content:
        # Reranker: ê°€ì¥ êµ¬ì²´ì ì¸ ì¿¼ë¦¬(main_query)ë¡œ ë¦¬ë­í‚¹
        final_ranked = reranker.rerank(
            main_query,
            docs_with_content,
            top_k=FINAL_TOPK,
            batch_size=32
        )
    else:
        final_ranked = top_candidates[:FINAL_TOPK]
    
    res["topk"] = final_ranked
    
    # Step 5: ë‹µë³€ ìƒì„±
    context_docs = []
    for docid in final_ranked[:3]:
        content = docs_dict.get(docid, '')
        if content:
            context_docs.append(content)
    
    context = " ".join(context_docs)
    res["answer"] = solar_client.generate_answer(messages, context)
    
    return res


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# ë©”ì¸ ì‹¤í–‰
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
if __name__ == "__main__":
    import sys
    from tqdm import tqdm
    
    # í‰ê°€ ë°ì´í„° ë¡œë“œ (JSONL í˜•ì‹)
    eval_path = "/root/IR/data/eval.jsonl"
    
    eval_data = []
    with open(eval_path, "r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if line:
                eval_data.append(json.loads(line))
    
    print(f"ğŸ“Š í‰ê°€ ë°ì´í„°: {len(eval_data)}ê°œ")
    print(f"âš™ï¸ ì„¤ì •:")
    print(f"   - USE_WEIGHTED_RRF: {USE_WEIGHTED_RRF}")
    print(f"   - USE_MULTI_QUERY_3: {USE_MULTI_QUERY_3}")
    print(f"   - W3_WEIGHTS: {W3_WEIGHTS}")
    print(f"   - RRF_K: {RRF_K}")
    print(f"   - TOP_CANDIDATES: {TOP_CANDIDATES}")
    
    results = []
    empty_count = 0
    
    for entry in tqdm(eval_data, desc="Processing"):
        eval_id = entry["eval_id"]
        messages = entry["msg"]
        
        result = answer_question_weighted_rrf(messages)
        
        if not result["topk"]:
            empty_count += 1
        
        results.append({
            "eval_id": eval_id,
            "standalone_query": result["standalone_query"],
            "topk": result["topk"],
            "answer": result["answer"],
            "references": []
        })
    
    # ê²°ê³¼ ì €ì¥
    output_path = "submission_weighted_rrf.csv"
    with open(output_path, "w", encoding="utf-8") as f:
        for r in results:
            f.write(json.dumps(r, ensure_ascii=False) + "\n")
    
    print(f"\nâœ… ê²°ê³¼ ì €ì¥: {output_path}")
    print(f"ğŸ“Œ Empty topk: {empty_count}/{len(eval_data)} ({empty_count/len(eval_data)*100:.1f}%)")
